{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5343372-4a7d-4860-9a50-c32b882f5bf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-13T13:54:45.376426Z",
     "iopub.status.busy": "2022-06-13T13:54:45.376018Z",
     "iopub.status.idle": "2022-06-13T13:55:03.283611Z",
     "shell.execute_reply": "2022-06-13T13:55:03.282419Z",
     "shell.execute_reply.started": "2022-06-13T13:54:45.376394Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#解压数据集\n",
    "!unzip data/data152113/signs.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc8753a-f75a-4710-964a-3215c0ca0f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T03:52:03.851299Z",
     "iopub.status.busy": "2022-06-15T03:52:03.850162Z",
     "iopub.status.idle": "2022-06-15T03:52:05.984495Z",
     "shell.execute_reply": "2022-06-15T03:52:05.983479Z",
     "shell.execute_reply.started": "2022-06-15T03:52:03.851246Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#导入库\n",
    "import io\n",
    "import os\n",
    "import paddle\n",
    "from PIL import Image\n",
    "import paddle.io as pio\n",
    "import paddle.vision.transforms as pt\n",
    "import paddle.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b612ae9d-4c65-48e9-81b7-e8307ce9d572",
   "metadata": {},
   "source": [
    "# 导入库后，第一次运行需要标签标注，标注完成后，不再需要运行此代码块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c64370-c262-44ec-bcf3-eeba7d289291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-13T13:55:25.631861Z",
     "iopub.status.busy": "2022-06-13T13:55:25.631057Z",
     "iopub.status.idle": "2022-06-13T13:57:42.992820Z",
     "shell.execute_reply": "2022-06-13T13:57:42.991784Z",
     "shell.execute_reply.started": "2022-06-13T13:55:25.631825Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#标签列表\n",
    "LABEL_MAP=[\"ratt\",\"ox\",\"tiger\",\"rabbit\",\"dragon\",\"snake\",\"horse\",\"goat\",\"monkey\",\"rooster\",\"dog\",\"pig\"]\n",
    "#根目录\n",
    "root = 'signs'\n",
    "#标注生成函数\n",
    "def Annotation(mode):\n",
    "    #先创建标注文件\n",
    "    with open('{}/{}.txt'.format(root,mode),'w') as f:\n",
    "        #训练，验证，测试三种文件夹路径\n",
    "        data_dir = '{}/{}'.format(root,mode)\n",
    "        #遍历文件夹,listdir函数可以返回data_dir下所有文件与文件夹列表\n",
    "        for path in os.listdir(data_dir):\n",
    "            #生成标签索引\n",
    "            label_index = LABEL_MAP.index(path)\n",
    "            #图像样本路径\n",
    "            img_path = '{}/{}'.format(data_dir,path)\n",
    "            #遍历所有图像样本\n",
    "            for image in os.listdir(img_path):\n",
    "                #单个图像的样本路径\n",
    "                image_file = '{}/{}'.format(img_path,image)\n",
    "                try:\n",
    "                    with open(image_file,'rb') as f_img:\n",
    "                        # io.BytesIO将字节对象转为Byte字节流数据,供Image.open使用\n",
    "                        #f_img.read([size]) 将文件数据作为字符串返回，可选参数size控制读取的字节数\n",
    "                        image=Image.open(io.BytesIO(f_img.read()))\n",
    "                        #调用load()方法将强行加载图像数据\n",
    "                        image.load()\n",
    "                        if image.mode=='RGB':\n",
    "                            #写入创建好的text文件\n",
    "                            f.write('{}\\t{}\\n'.format(image_file,label_index))\n",
    "                except:\n",
    "                    continue\n",
    "#生成三个数据集标注文件\n",
    "Annotation(mode = 'train')\n",
    "print('train annotation file created')\n",
    "Annotation(mode = 'valid')\n",
    "print('valid annotation file created')\n",
    "Annotation(mode = 'test')\n",
    "print('test annotation file created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05b7189-eb70-4b8f-b3fd-180c061948d6",
   "metadata": {},
   "source": [
    "# 自定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0d05bc-1b41-4815-bb41-5fba7d34fe30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T03:52:14.827492Z",
     "iopub.status.busy": "2022-06-15T03:52:14.826219Z",
     "iopub.status.idle": "2022-06-15T03:52:14.837525Z",
     "shell.execute_reply": "2022-06-15T03:52:14.836755Z",
     "shell.execute_reply.started": "2022-06-15T03:52:14.827437Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#自定义数据集\n",
    "class MyDataset(pio.Dataset):\n",
    "    def __init__(self, mode = 'train'):\n",
    "        super(MyDataset, self).__init__()\n",
    "        #判断mode参数\n",
    "        assert mode in ['train', 'test', 'valid'],'mode is one of train, test, valid'\n",
    "        self.data = []\n",
    "        #读取对应mode的索引记录\n",
    "        with open('signs/{}.txt'.format(mode)) as f:\n",
    "            #按行读取\n",
    "            for line in f.readlines():\n",
    "                #去除首尾制表符\n",
    "                info = line.strip().split('\\t')\n",
    "                if len(info) > 0:\n",
    "                    #将读取信息添加到data列表中\n",
    "                    self.data.append([info[0].strip(),info[1].strip()])\n",
    "        #定义预处理方法，增加样本多样性\n",
    "        if mode == 'train':\n",
    "            self.transforms = pt.Compose([\n",
    "                pt.RandomResizedCrop(size = 224),#随机裁剪大小，从原图裁剪为224*224\n",
    "                pt.RandomHorizontalFlip(0.5),#以0.5的概率随机水平翻转\n",
    "                pt.ToTensor(), #转变为张量模式\n",
    "                pt.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]) #归一化\n",
    "            ])\n",
    "        else:\n",
    "            #评估不需要增加样本多样性\n",
    "            self.transforms=pt.Compose([\n",
    "                pt.Resize(size=256),#先压缩到256*256\n",
    "                pt.RandomCrop(size=224),\n",
    "                pt.ToTensor(),\n",
    "                pt.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])#归一化\n",
    "            ])\n",
    "    def __getitem__(self,index):\n",
    "        #获取单个样本数据和标签\n",
    "        image_file,label = self.data[index]\n",
    "        image = Image.open(image_file)\n",
    "        #非RGB格式图像转化为RGB格式\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        #图像预处理\n",
    "        image = self.transforms(image)\n",
    "        #将标签转换为numpy形式\n",
    "        return image,np.array(label, dtype = 'int64')\n",
    "    def __len__(self):\n",
    "        return (len(self.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691418bf-d5e0-49a5-8081-fbbfb2f37d2c",
   "metadata": {},
   "source": [
    "# 创建数据集实例\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ac3ae-8db5-4e51-a253-0e11ff8e4982",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T03:52:18.719456Z",
     "iopub.status.busy": "2022-06-15T03:52:18.718736Z",
     "iopub.status.idle": "2022-06-15T03:52:18.735283Z",
     "shell.execute_reply": "2022-06-15T03:52:18.734682Z",
     "shell.execute_reply.started": "2022-06-15T03:52:18.719376Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#创建数据集实例\n",
    "train_data = MyDataset(mode = 'train')\n",
    "test_data = MyDataset(mode = 'test')\n",
    "valid_data = MyDataset(mode = 'valid')\n",
    "print ('训练集数目: {}, 验证集数目: {}, 测试集数目: {}'.format(len(train_data),len(valid_data),len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247e2951-a127-4ecb-8f87-ff2334fe278c",
   "metadata": {},
   "source": [
    "# VGG16网络组网"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1da532e-5a3e-4ba6-bb9d-5f6c3df28fe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T03:52:36.928542Z",
     "iopub.status.busy": "2022-06-15T03:52:36.928056Z",
     "iopub.status.idle": "2022-06-15T03:52:41.544962Z",
     "shell.execute_reply": "2022-06-15T03:52:41.544058Z",
     "shell.execute_reply.started": "2022-06-15T03:52:36.928506Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#模型组网VGG-16\n",
    "class VGG(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(VGG,self).__init__()\n",
    "        self.act = nn.ReLU()\n",
    "        #第一部分\n",
    "        self.c1_1=nn.Conv2D(3,64,3,1,1)\n",
    "        self.c1_2=nn.Conv2D(64,64,3,1,1)\n",
    "        self.m1=nn.MaxPool2D(kernel_size=2,stride=2)\n",
    "        #第二部分\n",
    "        self.c2_1=nn.Conv2D(64,128,3,1,1)\n",
    "        self.c2_2=nn.Conv2D(128,128,3,1,1)\n",
    "        self.m2=nn.MaxPool2D(kernel_size=2,stride=2)\n",
    "        #第三部分\n",
    "        self.c3_1=nn.Conv2D(128,256,3,1,1)\n",
    "        self.c3_2=nn.Conv2D(256,256,3,1,1)\n",
    "        self.c3_3=nn.Conv2D(256,256,3,1,1)\n",
    "        self.m3=nn.MaxPool2D(kernel_size=2,stride=2)\n",
    "        #第四部分\n",
    "        self.c4_1=nn.Conv2D(256,512,3,1,1)\n",
    "        self.c4_2=nn.Conv2D(512,512,3,1,1)\n",
    "        self.c4_3=nn.Conv2D(512,512,3,1,1)\n",
    "        self.m4=nn.MaxPool2D(kernel_size=2,stride=2)\n",
    "        #第五部分\n",
    "        self.c5_1=nn.Conv2D(512,512,3,1,1)\n",
    "        self.c5_2=nn.Conv2D(512,512,3,1,1)\n",
    "        self.c5_3=nn.Conv2D(512,512,3,1,1)\n",
    "        self.m5=nn.MaxPool2D(kernel_size=2,stride=2)\n",
    "        self.fl=nn.Flatten()\n",
    "        self.fc1=nn.Linear(in_features=512*7*7,out_features=4096)\n",
    "        self.fc2=nn.Linear(in_features=4096,out_features=4096)\n",
    "        self.fc3=nn.Linear(in_features=4096,out_features=12)\n",
    "        self.d=nn.Dropout()\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        x=self.c1_1(inputs)\n",
    "        x=self.act(x)\n",
    "        x=self.c1_2(x)\n",
    "        x=self.act(x)\n",
    "        x=self.m1(x)\n",
    "       \n",
    "        x=self.c2_1(x)\n",
    "        x=self.act(x)\n",
    "        x=self.c2_2(x)\n",
    "        x=self.act(x)\n",
    "        x=self.m2(x)\n",
    "\n",
    "        x=self.c3_1(x)\n",
    "        x=self.act(x)\n",
    "        x=self.c3_2(x)\n",
    "        x=self.act(x)\n",
    "        x=self.c3_3(x)\n",
    "        x=self.act(x)\n",
    "        x=self.m3(x)\n",
    "\n",
    "        x=self.c4_1(x)\n",
    "        x=self.act(x)\n",
    "        x=self.c4_2(x)\n",
    "        x=self.act(x)\n",
    "        x=self.c4_3(x)\n",
    "        x=self.act(x)\n",
    "        x=self.m4(x)\n",
    "\n",
    "        x=self.c5_1(x)\n",
    "        x=self.act(x)\n",
    "        x=self.c5_2(x)\n",
    "        x=self.act(x)\n",
    "        x=self.c5_3(x)\n",
    "        x=self.act(x)\n",
    "        x=self.m5(x)\n",
    "\n",
    "        #接分类层\n",
    "        x=self.fl(x)\n",
    "\n",
    "        x=self.fc1(x)\n",
    "        x=self.act(x)\n",
    "        x=self.d(x)\n",
    "\n",
    "        x=self.fc2(x)\n",
    "        x=self.act(x)\n",
    "        x=self.d(x)\n",
    "\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "model = VGG()\n",
    "paddle.summary(model,(1,3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0294b8-30df-4055-a8db-5bb39b3f9a26",
   "metadata": {},
   "source": [
    "# 开始训练，首先调整参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffa078c-bab0-493d-9d00-9d3e95053a0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T03:53:24.249464Z",
     "iopub.status.busy": "2022-06-15T03:53:24.248080Z",
     "iopub.status.idle": "2022-06-15T04:15:29.424450Z",
     "shell.execute_reply": "2022-06-15T04:15:29.423690Z",
     "shell.execute_reply.started": "2022-06-15T03:53:24.249391Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#超参设置\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "learning_rate = 0.0001\n",
    "#损失函数:cross_entropy为交叉熵损失，nll为negative log likelihood loss损失\n",
    "loss_function = 'cross_entropy'\n",
    "\n",
    "#开始训练\n",
    "train_d = paddle.io.DataLoader(train_data, batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "valid_d = paddle.io.DataLoader(valid_data, batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "def train(model,epochs,learning_rate,loss_function,batch_size):\n",
    "    use_gpu = True\n",
    "    #资源配置\n",
    "    paddle.set_device('gpu:0') if use_gpu else paddle.set_device('cpu')\n",
    "\n",
    "    cross_entropy = paddle.nn.CrossEntropyLoss()\n",
    "    log_softmax = paddle.nn.LogSoftmax(axis = 1)\n",
    "    nll = paddle.nn.NLLLoss()\n",
    "\n",
    "    #用正则化来提升精度\n",
    "    #opt = paddle.optimizer.Adam(learning_rate=learning_rate,parameters=model.parameters())\n",
    "    opt = paddle.optimizer.Momentum(learning_rate=learning_rate,parameters=model.parameters(),weight_decay=0.0001)\n",
    "    iter1 = 0\n",
    "    iters = []\n",
    "    losses = []\n",
    "    acces = []\n",
    "    model.train()\n",
    "    #进行数据记录\n",
    "    for epoch in range(epochs):\n",
    "        for batch_id,data in enumerate(train_d()):\n",
    "            image = data[0]\n",
    "            label = data[1]\n",
    "            label = paddle.reshape(label,(batch_size,1))\n",
    "            label_1 = label\n",
    "            predict = model (image)\n",
    "            if loss_function == 'cross_entropy':\n",
    "                loss = cross_entropy(predict,label)\n",
    "            elif loss_function == 'nll':\n",
    "                #predict = paddle.reshape(predict,(batch_size,1))\n",
    "                #predict = paddle.cast(predict,dtype='float32')\n",
    "                label = paddle.cast(label,dtype='int64')\n",
    "                predict = log_softmax(predict)\n",
    "                loss = nll(predict,label)\n",
    "            else:\n",
    "                print('wrong loss function')\n",
    "                exit\n",
    "            avg_loss=paddle.mean(loss)\n",
    "            predict_1=nn.functional.softmax(predict)\n",
    "            acc=paddle.metric.accuracy(predict_1,label_1)\n",
    "            \n",
    "            if batch_id % 10 ==0:\n",
    "                print('epoch_id:{}, batch_id:{}, train_loss:{}, train_acc:{}'.format(epoch,batch_id,avg_loss.numpy(),acc.numpy()))\n",
    "                iters.append(iter1)\n",
    "                acces.append(acc.numpy())\n",
    "                losses.append(avg_loss.numpy())\n",
    "                iter1 = iter1 + 10\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "        model.eval()\n",
    "        total_acc = []\n",
    "        total_loss = []\n",
    "        #验证数据\n",
    "        for batch_id,data in enumerate(valid_d()):\n",
    "            v_image=data[0]\n",
    "            v_label=data[1]\n",
    "            v_label=paddle.reshape(v_label,(batch_size,1))\n",
    "            v_label_1 = v_label\n",
    "            v_predict=model(v_image)\n",
    "            if loss_function == 'cross_entropy':\n",
    "                v_loss = nn.functional.cross_entropy(v_predict,v_label)\n",
    "            elif loss_function == 'nll':\n",
    "                #v_predict = paddle.reshape(predict,(batch_size,1))\n",
    "                #v_predict = paddle.cast(predict,dtype='float32')\n",
    "                v_label = paddle.cast(v_label,dtype='int64')\n",
    "                v_predict = log_softmax(v_predict)\n",
    "                v_loss = nll(v_predict,v_label)\n",
    "            else:\n",
    "                print('wrong loss function')\n",
    "                exit\n",
    "            v_avg_loss=paddle.mean(v_loss)\n",
    "            v_predict_1=nn.functional.softmax(v_predict)\n",
    "            v_acc=paddle.metric.accuracy(v_predict_1,v_label_1)\n",
    "            v_avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "            total_loss.append(v_avg_loss.numpy())\n",
    "            total_acc.append(v_acc.numpy())\n",
    "        mean_loss=np.mean(total_loss)\n",
    "        mean_acc=np.mean(total_acc)\n",
    "        print('epoch_id:{},  valid_loss:{},  valid_acc:{}  '.format(epoch,mean_loss,mean_acc))\n",
    "        model.train()\n",
    "    return iters, losses, acces\n",
    "model = VGG()\n",
    "#恢复训练\n",
    "params_file_path = './VGG16_0613.pdparams'\n",
    "param_dict = paddle.load(params_file_path)\n",
    "model.load_dict(param_dict)\n",
    "iters,losses,acces=train(model,epochs,learning_rate,loss_function,batch_size)\n",
    "paddle.save(model.state_dict(),'./VGG16_0615.pdparams')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ea238-105b-4a3e-91bc-a7dca865e5ec",
   "metadata": {},
   "source": [
    "# 测试训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77314bb-4f4a-4e37-8c31-778e5ef7f879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T05:25:06.066275Z",
     "iopub.status.busy": "2022-06-15T05:25:06.065779Z",
     "iopub.status.idle": "2022-06-15T05:25:26.111046Z",
     "shell.execute_reply": "2022-06-15T05:25:26.110388Z",
     "shell.execute_reply.started": "2022-06-15T05:25:06.066231Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score,classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "params_file_path = './VGG16_0615.pdparams'\n",
    "param_dict = paddle.load(params_file_path)\n",
    "model.load_dict(param_dict)\n",
    "test_d=paddle.io.DataLoader(test_data,batch_size=32,shuffle=True,drop_last=True)\n",
    "y_p = []\n",
    "y_t = []\n",
    "for batch, (test_X,test_y) in enumerate(test_d):\n",
    "    y_pred = model(test_X)\n",
    "    for i in y_pred:\n",
    "        y_p.append(np.argmax(i))\n",
    "    #y_p.append(y_pred)\n",
    "    for i in test_y:\n",
    "        y_t.append(int(i))\n",
    "\n",
    "cm = confusion_matrix(y_t,y_p)\n",
    "cm = pd.DataFrame(cm,columns=[\"ratt\",\"ox\",\"tiger\",\"rabbit\",\"dragon\",\"snake\",\"horse\",\"goat\",\"monkey\",\"rooster\",\"dog\",\"pig\"],index=[\"ratt\",\"ox\",\"tiger\",\"rabbit\",\"dragon\",\"snake\",\"horse\",\"goat\",\"monkey\",\"rooster\",\"dog\",\"pig\"])\n",
    "sns.heatmap(cm,cmap=\"YlGnBu_r\",fmt=\"d\",annot=True)\n",
    "\n",
    "print('f1_score:',f1_score(y_t,y_p,average='macro'))\n",
    "print('accuracy:',accuracy_score(y_t,y_p))\n",
    "print('error rate:',1-accuracy_score(y_t,y_p))\n",
    "print('precision:',precision_score(y_t,y_p,average='macro'))\n",
    "print('recall:',recall_score(y_t,y_p,average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3d400b-e3d7-4bc6-bcd8-643acfc74397",
   "metadata": {},
   "source": [
    "# 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9487153-fe73-4a42-a324-f38444ff40bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T05:25:37.405171Z",
     "iopub.status.busy": "2022-06-15T05:25:37.404554Z",
     "iopub.status.idle": "2022-06-15T05:25:43.057703Z",
     "shell.execute_reply": "2022-06-15T05:25:43.056717Z",
     "shell.execute_reply.started": "2022-06-15T05:25:37.405126Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABEL_MAP=[\"rat\",\"ox\",\"tiger\",\"rabbit\",\"dragon\",\"snake\",\"horse\",\"goat\",\"monkey\",\"rooster\",\"dog\",\"pig\"]\n",
    "#test文件夹进行测试模型\n",
    "root1='test'\n",
    "#将图片路径写入txt文本文件\n",
    "with open('{}.txt'.format(root1),'w') as f:\n",
    "    for image in os.listdir(root1):\n",
    "        #单个图像样本路径\n",
    "        image_file1='{}/{}'.format(root1,image)\n",
    "        f.write('{}\\n'.format(image_file1))\n",
    "#定义预处理方式\n",
    "def transform(img):\n",
    "    if img.mode !='RGB':\n",
    "        img=img.convert('RGB')\n",
    "    transforms=pt.Compose([\n",
    "                pt.Resize(size=256),#先压缩到256*256\n",
    "                pt.RandomCrop(size=224),\n",
    "                pt.ToTensor(),\n",
    "                pt.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])#归一化\n",
    "            ])\n",
    "    img=transforms(img)\n",
    "    img=paddle.reshape(img,(1,3,224,224))\n",
    "    return img\n",
    "\n",
    "#将创建好的文本中图片路径写入一个列表\n",
    "test_list=[]\n",
    "with open('test.txt') as f:\n",
    "    img=f.readlines()\n",
    "    for i in range(len(img)):\n",
    "        test_list.append(img[i].strip())\n",
    "    print(test_list)\n",
    "#加载模型\n",
    "model=VGG()\n",
    "params_file_path = './VGG16_0615.pdparams'\n",
    "param_dict = paddle.load(params_file_path)\n",
    "model.load_dict(param_dict)\n",
    "model.eval()\n",
    "for i in range(len(test_list)):\n",
    "    img=Image.open(test_list[i])\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    img=transform(img)\n",
    "    result=model(img)\n",
    "    result=paddle.argmax(result[0])\n",
    "    plt.title('predict:{}'.format(LABEL_MAP[result]))\n",
    "    plt.axis('on')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
