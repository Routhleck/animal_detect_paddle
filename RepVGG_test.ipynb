{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5343372-4a7d-4860-9a50-c32b882f5bf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T03:33:09.482291Z",
     "iopub.status.busy": "2022-06-11T03:33:09.481690Z",
     "iopub.status.idle": "2022-06-11T03:33:26.664488Z",
     "shell.execute_reply": "2022-06-11T03:33:26.663773Z",
     "shell.execute_reply.started": "2022-06-11T03:33:09.482255Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#解压数据集\n",
    "!unzip data/data152113/signs.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc8753a-f75a-4710-964a-3215c0ca0f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T11:29:57.449372Z",
     "iopub.status.busy": "2022-06-17T11:29:57.448861Z",
     "iopub.status.idle": "2022-06-17T11:29:59.149526Z",
     "shell.execute_reply": "2022-06-17T11:29:59.148616Z",
     "shell.execute_reply.started": "2022-06-17T11:29:57.449332Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#导入库\n",
    "import io\n",
    "import os\n",
    "import paddle\n",
    "from PIL import Image\n",
    "import paddle.io as pio\n",
    "import paddle.vision.transforms as pt\n",
    "import paddle.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b612ae9d-4c65-48e9-81b7-e8307ce9d572",
   "metadata": {},
   "source": [
    "# 导入库后，第一次运行需要标签标注，标注完成后，不再需要运行此代码块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c64370-c262-44ec-bcf3-eeba7d289291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T11:30:00.788424Z",
     "iopub.status.busy": "2022-06-17T11:30:00.787830Z",
     "iopub.status.idle": "2022-06-17T11:32:28.185232Z",
     "shell.execute_reply": "2022-06-17T11:32:28.184305Z",
     "shell.execute_reply.started": "2022-06-17T11:30:00.788377Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#标签列表\n",
    "LABEL_MAP=[\"ratt\",\"ox\",\"tiger\",\"rabbit\",\"dragon\",\"snake\",\"horse\",\"goat\",\"monkey\",\"rooster\",\"dog\",\"pig\"]\n",
    "#根目录\n",
    "root = 'signs'\n",
    "#标注生成函数\n",
    "def Annotation(mode):\n",
    "    #先创建标注文件\n",
    "    with open('{}/{}.txt'.format(root,mode),'w') as f:\n",
    "        #训练，验证，测试三种文件夹路径\n",
    "        data_dir = '{}/{}'.format(root,mode)\n",
    "        #遍历文件夹,listdir函数可以返回data_dir下所有文件与文件夹列表\n",
    "        for path in os.listdir(data_dir):\n",
    "            #生成标签索引\n",
    "            label_index = LABEL_MAP.index(path)\n",
    "            #图像样本路径\n",
    "            img_path = '{}/{}'.format(data_dir,path)\n",
    "            #遍历所有图像样本\n",
    "            for image in os.listdir(img_path):\n",
    "                #单个图像的样本路径\n",
    "                image_file = '{}/{}'.format(img_path,image)\n",
    "                try:\n",
    "                    with open(image_file,'rb') as f_img:\n",
    "                        # io.BytesIO将字节对象转为Byte字节流数据,供Image.open使用\n",
    "                        #f_img.read([size]) 将文件数据作为字符串返回，可选参数size控制读取的字节数\n",
    "                        image=Image.open(io.BytesIO(f_img.read()))\n",
    "                        #调用load()方法将强行加载图像数据\n",
    "                        image.load()\n",
    "                        if image.mode=='RGB':\n",
    "                            #写入创建好的text文件\n",
    "                            f.write('{}\\t{}\\n'.format(image_file,label_index))\n",
    "                except:\n",
    "                    continue\n",
    "#生成三个数据集标注文件\n",
    "Annotation(mode = 'train')\n",
    "Annotation(mode = 'valid')\n",
    "Annotation(mode = 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05b7189-eb70-4b8f-b3fd-180c061948d6",
   "metadata": {},
   "source": [
    "# 自定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f526a-e311-4ae0-b91e-42700d4d237e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T11:32:52.995099Z",
     "iopub.status.busy": "2022-06-17T11:32:52.993984Z",
     "iopub.status.idle": "2022-06-17T11:32:53.005545Z",
     "shell.execute_reply": "2022-06-17T11:32:53.004539Z",
     "shell.execute_reply.started": "2022-06-17T11:32:52.995054Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#自定义数据集\n",
    "class MyDataset(pio.Dataset):\n",
    "    def __init__(self, mode = 'train'):\n",
    "        super(MyDataset, self).__init__()\n",
    "        #判断mode参数\n",
    "        assert mode in ['train', 'test', 'valid'],'mode is one of train, test, valid'\n",
    "        self.data = []\n",
    "        #读取对应mode的索引记录\n",
    "        with open('signs/{}.txt'.format(mode)) as f:\n",
    "            #按行读取\n",
    "            for line in f.readlines():\n",
    "                #去除首尾制表符\n",
    "                info = line.strip().split('\\t')\n",
    "                if len(info) > 0:\n",
    "                    #将读取信息添加到data列表中\n",
    "                    self.data.append([info[0].strip(),info[1].strip()])\n",
    "        #定义预处理方法，增加样本多样性\n",
    "        if mode == 'train':\n",
    "            self.transforms = pt.Compose([\n",
    "                pt.RandomResizedCrop(size = 224),#随机裁剪大小，从原图裁剪为224*224\n",
    "                pt.RandomHorizontalFlip(0.5),#以0.5的概率随机水平翻转\n",
    "                pt.ToTensor(), #转变为张量模式\n",
    "                pt.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]) #归一化\n",
    "            ])\n",
    "        else:\n",
    "            #评估不需要增加样本多样性\n",
    "            self.transforms=pt.Compose([\n",
    "                pt.Resize(size=256),#先压缩到256*256\n",
    "                pt.RandomCrop(size=224),\n",
    "                pt.ToTensor(),\n",
    "                pt.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])#归一化\n",
    "            ])\n",
    "    def __getitem__(self,index):\n",
    "        #获取单个样本数据和标签\n",
    "        image_file,label = self.data[index]\n",
    "        image = Image.open(image_file)\n",
    "        #非RGB格式图像转化为RGB格式\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        #图像预处理\n",
    "        image = self.transforms(image)\n",
    "        #将标签转换为numpy形式\n",
    "        return image,np.array(label, dtype = 'int64')\n",
    "    def __len__(self):\n",
    "        return (len(self.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84156c5c-ff41-413d-8302-19ffdef68c55",
   "metadata": {},
   "source": [
    "# 创建数据集实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1b7a7b-b613-4566-baba-32b943356acb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T11:32:55.345000Z",
     "iopub.status.busy": "2022-06-17T11:32:55.343807Z",
     "iopub.status.idle": "2022-06-17T11:32:55.358998Z",
     "shell.execute_reply": "2022-06-17T11:32:55.358257Z",
     "shell.execute_reply.started": "2022-06-17T11:32:55.344956Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#创建数据集实例\n",
    "train_data = MyDataset(mode = 'train')\n",
    "test_data = MyDataset(mode = 'test')\n",
    "valid_data = MyDataset(mode = 'valid')\n",
    "print ('训练集数目: {}, 验证集数目: {}, 测试集数目: {}'.format(len(train_data),len(valid_data),len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c13827-8a5f-4b58-a63b-324987bdddb6",
   "metadata": {},
   "source": [
    "# 模型组网\n",
    "## 构建ConvBN模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4900d2d8-33ee-4653-bf97-f3a710f70efa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T11:32:58.561970Z",
     "iopub.status.busy": "2022-06-17T11:32:58.560865Z",
     "iopub.status.idle": "2022-06-17T11:32:58.567973Z",
     "shell.execute_reply": "2022-06-17T11:32:58.566900Z",
     "shell.execute_reply.started": "2022-06-17T11:32:58.561925Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#模型组网RepVGG\n",
    "\n",
    "#构建ConvBN模块\n",
    "class ConvBN(nn.Layer):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
    "        super(ConvBN, self).__init__()\n",
    "        self.conv = nn.Conv2D(in_channels=in_channels, out_channels=out_channels,\n",
    "                              kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias_attr=False)\n",
    "        self.bn = nn.BatchNorm2D(num_features=out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 卷积\n",
    "        y = self.conv(x)\n",
    "        \n",
    "        # 归一化\n",
    "        y = self.bn(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8648439b-bb24-4bd7-8e9b-e87a1e638729",
   "metadata": {},
   "source": [
    "## 构建RepVGGBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25caa281-7daa-4bcc-b8fd-33cb0ef6d65c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T11:33:00.218759Z",
     "iopub.status.busy": "2022-06-17T11:33:00.218391Z",
     "iopub.status.idle": "2022-06-17T11:33:00.236720Z",
     "shell.execute_reply": "2022-06-17T11:33:00.235635Z",
     "shell.execute_reply.started": "2022-06-17T11:33:00.218724Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#构建RepVGGBlock\n",
    "class RepVGGBlock(nn.Layer):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros'):\n",
    "        super(RepVGGBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.groups = groups\n",
    "        self.padding_mode = padding_mode\n",
    "\n",
    "        assert kernel_size == 3\n",
    "        assert padding == 1\n",
    "\n",
    "        padding_11 = padding - kernel_size // 2\n",
    "\n",
    "        self.nonlinearity = nn.ReLU()\n",
    "\n",
    "        self.rbr_identity = nn.BatchNorm2D(\n",
    "            num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
    "        self.rbr_dense = ConvBN(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
    "        self.rbr_1x1 = ConvBN(in_channels=in_channels, out_channels=out_channels,\n",
    "                               kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # 判断模型状态，若处于评估预测状态，则启用重排后的模型进行前向计算\n",
    "        if hasattr(self, 'rbr_reparam'):\n",
    "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
    "        \n",
    "        # 若处于训练状态下\n",
    "        if self.rbr_identity is None:\n",
    "            id_out = 0\n",
    "        else:\n",
    "            # 如果 BN 层存在，则计算 BN\n",
    "            id_out = self.rbr_identity(inputs)\n",
    "        \n",
    "        # relu(3X3 ConvBN + 1X1 ConvBN + bn or 0)\n",
    "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
    "    \n",
    "    # 重写 eval 函数\n",
    "    # 在模型评估时对参数进行重新排列\n",
    "    # 将原来的 3X3 ConvBN、1X1 ConvBN 和 bn 的参数重新排列合并为单个 3X3 的 conv\n",
    "    def eval(self):\n",
    "        if not hasattr(self, 'rbr_reparam'):\n",
    "            self.rbr_reparam = nn.Conv2D(in_channels=self.in_channels, out_channels=self.out_channels, kernel_size=self.kernel_size, stride=self.stride,\n",
    "                                         padding=self.padding, dilation=self.dilation, groups=self.groups, padding_mode=self.padding_mode)\n",
    "        self.training = False\n",
    "\n",
    "        # 计算重排后的参数\n",
    "        # 具体的计算方式请参考上述的图例\n",
    "        # 或者下方的计算代码\n",
    "        kernel, bias = self.get_equivalent_kernel_bias()\n",
    "\n",
    "        # 设置新的参数\n",
    "        self.rbr_reparam.weight.set_value(kernel)\n",
    "        self.rbr_reparam.bias.set_value(bias)\n",
    "\n",
    "        for layer in self.sublayers():\n",
    "            layer.eval()\n",
    "\n",
    "    def get_equivalent_kernel_bias(self):\n",
    "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
    "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
    "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
    "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
    "\n",
    "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
    "        if kernel1x1 is None:\n",
    "            return 0\n",
    "        else:\n",
    "            return nn.functional.pad(kernel1x1, [1, 1, 1, 1])\n",
    "\n",
    "    def _fuse_bn_tensor(self, branch):\n",
    "        if branch is None:\n",
    "            return 0, 0\n",
    "        if isinstance(branch, ConvBN):\n",
    "            kernel = branch.conv.weight\n",
    "            running_mean = branch.bn._mean\n",
    "            running_var = branch.bn._variance\n",
    "            gamma = branch.bn.weight\n",
    "            beta = branch.bn.bias\n",
    "            eps = branch.bn._epsilon\n",
    "        else:\n",
    "            assert isinstance(branch, nn.BatchNorm2D)\n",
    "            if not hasattr(self, 'id_tensor'):\n",
    "                input_dim = self.in_channels // self.groups\n",
    "                kernel_value = np.zeros(\n",
    "                    (self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
    "                for i in range(self.in_channels):\n",
    "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
    "                self.id_tensor = paddle.to_tensor(kernel_value)\n",
    "            kernel = self.id_tensor\n",
    "            running_mean = branch._mean\n",
    "            running_var = branch._variance\n",
    "            gamma = branch.weight\n",
    "            beta = branch.bias\n",
    "            eps = branch._epsilon\n",
    "        std = (running_var + eps).sqrt()\n",
    "        t = (gamma / std).reshape((-1, 1, 1, 1))\n",
    "        return kernel * t, beta - running_mean * gamma / std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ce25b3-31a3-4131-8fab-5e81fd11f6d7",
   "metadata": {},
   "source": [
    "## 构建RepVGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c06977b-baef-4500-9c08-6379093c9298",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T11:33:03.280449Z",
     "iopub.status.busy": "2022-06-17T11:33:03.279858Z",
     "iopub.status.idle": "2022-06-17T11:33:03.292398Z",
     "shell.execute_reply": "2022-06-17T11:33:03.291793Z",
     "shell.execute_reply.started": "2022-06-17T11:33:03.280400Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#构建RepVGG\n",
    "class RepVGG(nn.Layer):\n",
    "\n",
    "    def __init__(self, num_blocks, width_multiplier=None, override_groups_map=None, class_dim=12):\n",
    "        super(RepVGG, self).__init__()\n",
    "\n",
    "        assert len(width_multiplier) == 4\n",
    "        self.override_groups_map = override_groups_map or dict()\n",
    "\n",
    "        assert 0 not in self.override_groups_map\n",
    "\n",
    "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
    "        \n",
    "        # stage0：一个 RepVGGBlock\n",
    "        self.stage0 = RepVGGBlock(\n",
    "            in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1)\n",
    "        self.cur_layer_idx = 1\n",
    "\n",
    "        # stage1-4：根据配置文件生成对应数量的 RepVGGBlock\n",
    "        self.stage1 = self._make_stage(\n",
    "            int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
    "        self.stage2 = self._make_stage(\n",
    "            int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
    "        self.stage3 = self._make_stage(\n",
    "            int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
    "        self.stage4 = self._make_stage(\n",
    "            int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
    "        self.gap = nn.AdaptiveAvgPool2D(output_size=1)\n",
    "        self.linear = nn.Linear(int(512 * width_multiplier[3]), class_dim)\n",
    "\n",
    "    def _make_stage(self, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        blocks = []\n",
    "        for stride in strides:\n",
    "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
    "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
    "                                      stride=stride, padding=1, groups=cur_groups))\n",
    "            self.in_planes = planes\n",
    "            self.cur_layer_idx += 1\n",
    "        return nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # stage0-5\n",
    "        out = self.stage0(x)\n",
    "        out = self.stage1(out)\n",
    "        out = self.stage2(out)\n",
    "        out = self.stage3(out)\n",
    "        out = self.stage4(out)\n",
    "\n",
    "        # 平均池化\n",
    "        out = self.gap(out)\n",
    "\n",
    "        # 向量展开\n",
    "        out = paddle.flatten(out, start_axis=1)\n",
    "\n",
    "        # 线性变换\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0275e9d5-c67f-4c4d-822f-36ef63a1ac8e",
   "metadata": {},
   "source": [
    "# RepVGG模型实例化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1021c2-4f5b-4fc7-bca6-54c3f70b9538",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T11:33:06.585071Z",
     "iopub.status.busy": "2022-06-17T11:33:06.584461Z",
     "iopub.status.idle": "2022-06-17T11:33:10.944948Z",
     "shell.execute_reply": "2022-06-17T11:33:10.944374Z",
     "shell.execute_reply.started": "2022-06-17T11:33:06.585028Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = RepVGG(num_blocks=[2, 4, 14, 1],\n",
    "    width_multiplier=[0.75, 0.75, 0.75, 2.5], \n",
    "    override_groups_map=None)\n",
    "paddle.summary(model,input_size=(1,3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0294b8-30df-4055-a8db-5bb39b3f9a26",
   "metadata": {},
   "source": [
    "# 开始训练，首先调整参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffa078c-bab0-493d-9d00-9d3e95053a0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T11:37:41.285857Z",
     "iopub.status.busy": "2022-06-17T11:37:41.284974Z",
     "iopub.status.idle": "2022-06-17T12:30:10.748843Z",
     "shell.execute_reply": "2022-06-17T12:30:10.747862Z",
     "shell.execute_reply.started": "2022-06-17T11:37:41.285808Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#超参设置\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "learning_rate = 0.0001\n",
    "#损失函数:cross_entropy为交叉熵损失，nll为negative log likelihood loss损失\n",
    "loss_function = 'cross_entropy'\n",
    "\n",
    "#开始训练\n",
    "train_d = paddle.io.DataLoader(train_data, batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "valid_d = paddle.io.DataLoader(valid_data, batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "def train(model,epochs,learning_rate,loss_function,batch_size):\n",
    "    use_gpu = True\n",
    "    #资源配置\n",
    "    paddle.set_device('gpu:0') if use_gpu else paddle.set_device('cpu')\n",
    "\n",
    "    cross_entropy = paddle.nn.CrossEntropyLoss()\n",
    "    log_softmax = paddle.nn.LogSoftmax(axis = 1)\n",
    "    nll = paddle.nn.NLLLoss()\n",
    "\n",
    "    #用正则化来提升精度\n",
    "    opt = paddle.optimizer.Adam(learning_rate=learning_rate,parameters=model.parameters())\n",
    "    #opt = paddle.optimizer.Momentum(learning_rate=learning_rate,parameters=model.parameters(),weight_decay=0.0001)\n",
    "    iter1 = 0\n",
    "    iters = []\n",
    "    losses = []\n",
    "    acces = []\n",
    "    model.train()\n",
    "    #进行数据记录\n",
    "    for epoch in range(epochs):\n",
    "        for batch_id,data in enumerate(train_d()):\n",
    "            image = data[0]\n",
    "            label = data[1]\n",
    "            label = paddle.reshape(label,(batch_size,1))\n",
    "            label_1 = label\n",
    "            predict = model (image)\n",
    "            if loss_function == 'cross_entropy':\n",
    "                loss = cross_entropy(predict,label)\n",
    "            elif loss_function == 'nll':\n",
    "                #predict = paddle.reshape(predict,(batch_size,1))\n",
    "                #predict = paddle.cast(predict,dtype='float32')\n",
    "                label = paddle.cast(label,dtype='int64')\n",
    "                predict = log_softmax(predict)\n",
    "                loss = nll(predict,label)\n",
    "            else:\n",
    "                print('wrong loss function')\n",
    "                exit\n",
    "            avg_loss=paddle.mean(loss)\n",
    "            predict_1=nn.functional.softmax(predict)\n",
    "            acc=paddle.metric.accuracy(predict_1,label_1)\n",
    "            \n",
    "            if batch_id % 10 ==0:\n",
    "                print('epoch_id:{}, batch_id:{}, train_loss:{}, train_acc:{}'.format(epoch,batch_id,avg_loss.numpy(),acc.numpy()))\n",
    "                iters.append(iter1)\n",
    "                acces.append(acc.numpy())\n",
    "                losses.append(avg_loss.numpy())\n",
    "                iter1 = iter1 + 10\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "        model.eval()\n",
    "        total_acc = []\n",
    "        total_loss = []\n",
    "        #验证数据\n",
    "        for batch_id,data in enumerate(valid_d()):\n",
    "            v_image=data[0]\n",
    "            v_label=data[1]\n",
    "            v_label=paddle.reshape(v_label,(batch_size,1))\n",
    "            v_label_1 = v_label\n",
    "            v_predict=model(v_image)\n",
    "            if loss_function == 'cross_entropy':\n",
    "                v_loss = nn.functional.cross_entropy(v_predict,v_label)\n",
    "            elif loss_function == 'nll':\n",
    "                #v_predict = paddle.reshape(predict,(batch_size,1))\n",
    "                #v_predict = paddle.cast(predict,dtype='float32')\n",
    "                v_label = paddle.cast(v_label,dtype='int64')\n",
    "                v_predict = log_softmax(v_predict)\n",
    "                v_loss = nll(v_predict,v_label)\n",
    "            else:\n",
    "                print('wrong loss function')\n",
    "                exit\n",
    "            v_avg_loss=paddle.mean(v_loss)\n",
    "            v_predict_1=nn.functional.softmax(v_predict)\n",
    "            v_acc=paddle.metric.accuracy(v_predict_1,v_label_1)\n",
    "            v_avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "            total_loss.append(v_avg_loss.numpy())\n",
    "            total_acc.append(v_acc.numpy())\n",
    "        mean_loss=np.mean(total_loss)\n",
    "        mean_acc=np.mean(total_acc)\n",
    "        print('epoch_id:{},  valid_loss:{},  valid_acc:{}  '.format(epoch,mean_loss,mean_acc))\n",
    "        model.train()\n",
    "    return iters, losses, acces\n",
    "model = RepVGG(num_blocks=[2, 4, 14, 1],\n",
    "    width_multiplier=[0.75, 0.75, 0.75, 2.5], \n",
    "    override_groups_map=None)\n",
    "#恢复训练\n",
    "#params_file_path = './REPVGG_AC.pdparams'\n",
    "#param_dict = paddle.load(params_file_path)\n",
    "#model.load_dict(param_dict)\n",
    "iters,losses,acces=train(model,epochs,learning_rate,loss_function,batch_size)\n",
    "paddle.save(model.state_dict(),'./REPVGG_0617.pdparams')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ea238-105b-4a3e-91bc-a7dca865e5ec",
   "metadata": {},
   "source": [
    "# 测试训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77314bb-4f4a-4e37-8c31-778e5ef7f879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T12:33:09.126343Z",
     "iopub.status.busy": "2022-06-17T12:33:09.125826Z",
     "iopub.status.idle": "2022-06-17T12:33:25.007479Z",
     "shell.execute_reply": "2022-06-17T12:33:25.006713Z",
     "shell.execute_reply.started": "2022-06-17T12:33:09.126300Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score,classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "params_file_path = './REPVGG_0617.pdparams'\n",
    "param_dict = paddle.load(params_file_path)\n",
    "model.load_dict(param_dict)\n",
    "test_d=paddle.io.DataLoader(test_data,batch_size=32,shuffle=True,drop_last=True)\n",
    "y_p = []\n",
    "y_t = []\n",
    "for batch, (test_X,test_y) in enumerate(test_d):\n",
    "    y_pred = model(test_X)\n",
    "    for i in y_pred:\n",
    "        y_p.append(np.argmax(i))\n",
    "    #y_p.append(y_pred)\n",
    "    for i in test_y:\n",
    "        y_t.append(int(i))\n",
    "\n",
    "cm = confusion_matrix(y_t,y_p)\n",
    "cm = pd.DataFrame(cm,columns=[\"ratt\",\"ox\",\"tiger\",\"rabbit\",\"dragon\",\"snake\",\"horse\",\"goat\",\"monkey\",\"rooster\",\"dog\",\"pig\"],index=[\"ratt\",\"ox\",\"tiger\",\"rabbit\",\"dragon\",\"snake\",\"horse\",\"goat\",\"monkey\",\"rooster\",\"dog\",\"pig\"])\n",
    "sns.heatmap(cm,cmap=\"YlGnBu_r\",fmt=\"d\",annot=True)\n",
    "\n",
    "print('f1_score:',f1_score(y_t,y_p,average='macro'))\n",
    "print('accuracy:',accuracy_score(y_t,y_p))\n",
    "print('error rate:',1-accuracy_score(y_t,y_p))\n",
    "print('precision:',precision_score(y_t,y_p,average='macro'))\n",
    "print('recall:',recall_score(y_t,y_p,average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c313cb-7772-468b-9229-a8206956be54",
   "metadata": {},
   "source": [
    "# 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f2b073-e3cd-440f-badb-5a2f048d98ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T12:35:09.359186Z",
     "iopub.status.busy": "2022-06-17T12:35:09.358653Z",
     "iopub.status.idle": "2022-06-17T12:35:12.457442Z",
     "shell.execute_reply": "2022-06-17T12:35:12.456831Z",
     "shell.execute_reply.started": "2022-06-17T12:35:09.359145Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABEL_MAP=[\"rat\",\"ox\",\"tiger\",\"rabbit\",\"dragon\",\"snake\",\"horse\",\"goat\",\"monkey\",\"rooster\",\"dog\",\"pig\"]\n",
    "#test文件夹进行测试模型\n",
    "root1='test'\n",
    "#将图片路径写入txt文本文件\n",
    "with open('{}.txt'.format(root1),'w') as f:\n",
    "    for image in os.listdir(root1):\n",
    "        #单个图像样本路径\n",
    "        image_file1='{}/{}'.format(root1,image)\n",
    "        f.write('{}\\n'.format(image_file1))\n",
    "#定义预处理方式\n",
    "def transform(img):\n",
    "    if img.mode !='RGB':\n",
    "        img=img.convert('RGB')\n",
    "    transforms=pt.Compose([\n",
    "                pt.Resize(size=256),#先压缩到256*256\n",
    "                pt.RandomCrop(size=224),\n",
    "                pt.ToTensor(),\n",
    "                pt.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])#归一化\n",
    "            ])\n",
    "    img=transforms(img)\n",
    "    img=paddle.reshape(img,(1,3,224,224))\n",
    "    return img\n",
    "\n",
    "#将创建好的文本中图片路径写入一个列表\n",
    "test_list=[]\n",
    "with open('test.txt') as f:\n",
    "    img=f.readlines()\n",
    "    for i in range(len(img)):\n",
    "        test_list.append(img[i].strip())\n",
    "    print(test_list)\n",
    "#加载模型\n",
    "model = RepVGG(num_blocks=[2, 4, 14, 1],\n",
    "    width_multiplier=[0.75, 0.75, 0.75, 2.5], \n",
    "    override_groups_map=None)\n",
    "params_file_path = './REPVGG_0617.pdparams'\n",
    "param_dict = paddle.load(params_file_path)\n",
    "model.load_dict(param_dict)\n",
    "model.eval()\n",
    "for i in range(len(test_list)):\n",
    "    img=Image.open(test_list[i])\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    img=transform(img)\n",
    "    result=model(img)\n",
    "    result=paddle.argmax(result[0])\n",
    "    plt.title('predict:{}'.format(LABEL_MAP[result]))\n",
    "    plt.axis('on')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
